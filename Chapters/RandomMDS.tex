\chapter{A result for random MDS code over a large fields}
\label{sec:random-mds} 

Next, we prove that for sufficiently large prime-order fields, `almost all' Massey (n,t)-secret sharing schemes over $\F_{p(n)}$ for sufficiently large $p(n)$, are leakage-resilient for smaller values of $t$ - all the way down to $t\geq (0.5 +\delta)n$, for every constant $\delta>0$. 

We will need a few technical linear-algebraic  claims. The first one is a certain generalization of the rank method used in the communication complexity literature, stating that boolean matrices with $a$ distinct rows have rank at least $\log{a}$ over the reals. We show that over any field, a matrix with $a$ distinct rows where the entries in every column belong to a set of constant size, has rank at least $O(\log{a})$. 

\begin{claim}\label{rank}
Let $M\in\F^{a\times b}_p$ denote a matrix with distinct rows, where $a=2^{cb}$ for some constants 
$c > 0$ and $T\geq 2$. Assume further, that for every $y\in[b]$, there exists a set $V_y\subseteq \F_p$ of size $T$ such that for all $x\in[a]$ and $y\in[b]$ it holds that $M[x,y]\in V_y$. Then $rank(M)\geq  \frac{c}{\log(T)}b$.
\end{claim}

%\TODO{We need to explain how the secret sharing scheme is generated from the code.
%Make sure that all dimensions we use are precise and not off by 1.
%Sould be part of the preliminaries, and briefly mention in the intro as well.}

\begin{proof}
Let $r$ be the rank of $M$. Let $M'=(v_1;\ldots;v_r)$ be a submatrix of $M$, whose rows form a basis for the row space of $M$. Let $I$ denote the (index) set of $r$ independent columns of $M'$. w.l.o.g.\ assume that $I=[r]$. Let $M''=M'[*,I]$. Then, every vector $u\in V_1\times\ldots\times V_b\cap \rowspan{M}$ equals some $h\cdot M'$, where $h\cdot M''\in V_1\times\ldots\times V_r$. As $M''$ is invertible, $h$ is of the form
$h = u[I] {M''}^{-1}$ - that is, $u[I]$ uniquely determines $h$. 
As there are at most $T^r$ such $u[I]$-values, 
\begin{align}
\left|V_1\times\ldots\times V_b \cap \rowspan{M}\right|\leq T^r
\end{align}

So, to generate all (distinct) $a$ rows of $M$, we would need $r\geq \frac{c}{\log(T)}b$.
\end{proof}

Let $C^\bot$ denote a $\mdscode{n}{\dualcodedim}{\F_p}$ generated by the matrix $H=(h_1;\ldots;h_n)$.
For a number $T$ and a vector $\vec{V}=(V_1,\ldots,V_n)\in {\binom{\F_p}{T}}^n$ (each $V_i$ is a set of $T$ field elements), let us denote  $$\Bad{I}{\vec{V}}(C^\bot) = \left\{\beta\in\F^{\dualcodedim}_p| \forall i\in I \text{ and } \ip{\beta,h_i} \in V_i\right\} ,$$ 
and $$\Bad{\vec{V}}{\delta}(C^\bot)=\bigcup_{I\subseteq [n]\text{ of size }(1-\delta) n}\Bad{I}{\vec{V}}(C^\bot).$$
\noindent For a constant $c$ we also denote
$$\Bad{\delta}{c}=\bigcup_{\vec{V}\in{\binom{\F_p}{T}}^n}\left\{C^\bot:\left|\Bad{\vec{V}}{\delta}(C^\bot)\right|\geq c^n\right\}.$$
For a vector $v\in \F^n_p$ we write $v\in\vec{V}$ to mean that $v_i\in V_i$ for all $i \in [n]$. 

The following lemma is a key lemma in our analysis. Roughly, it states that for a small $T$, `most' MDS codes with certain parameters don't have `many' `bad' codeword, such that `many' coordinates out of each bad codeword fall in a set of size $T$ (sets may differ for different coordinates).

\begin{lemma}
\label{lem:sim}
Let $p(n) \geq 2^n$ be a function returning primes, and let $c>1$, $T\geq 2,0<\delta<1/2$ be constants. We further require that $\log{c}>\Ent{\delta}$. 
Consider the set $\mathcal{C}^\bot$ of linear $\mdscode{n}{\dualcodedim}{\F_p}$ codes $C^\bot$, where $\Omega(n)=\dualcodedim\leq (1-2\delta)n$, and the uniform probability distribution over $\mathcal{C}^\bot$. 
%Let $\Bad{\delta}{c}=\bigcup_{\vec{V}\in{\binom{\F_p}{T}}^n}\left\{C^\bot:\left|\Bad{\vec{V}}{\delta}(C^\bot)\right|\geq c^n\right\}$.
Then,
$$Pr_{C^\bot\in \mathcal{C}^\bot}\left[C^\bot \in \Bad{\delta}{c}\right]=neg(n)$$

%We refer to (the few) linear $\mdscode{n}{\dualcodedim}{\F_p}$ code falling in $\Bad{\delta}{c}$ as \emph{bad for} $(n,\delta,c,T)$ ($p$ is determined by $n$).
%In particular, it implies that for a sufficiently large $n$ and $T,c,\delta$ as above, a code $C^\bot$ which is not bad for $(n,\delta,c,T)$ exists.
\end{lemma}

\begin{proof}
Fix a sufficiently large $n$ and $p(n),c,T,\delta,\dualcodedim$ as in the lemma. Consider some linear MDS code $C^\bot\in \Bad{\delta}{c}$. % - in the analysis below, we will in particular show that linear MDS codes with the required parameters do exist.
So, by definition $\Bad{\delta}{c}$, there exists some $\vec{V}$ such that $\Bad{\vec{V}}{\delta}(C^\bot)\geq c^n$. 
By the assumption that $c>\Ent{\delta}$, there exists a set of coordinates $I$ of size $(1-\delta)n$, so that  $\Bad{I}{\vec{V}}(C^\bot)$ is of size $\tilde{\Omega}(2^{(\log(c)-\Ent{\delta})n})$. This follows by a simple averaging argument, and approximating the number of $I$'s of size $(1-\delta)n$ using estimation~\ref{eq:bin} (note that $\Ent{1-\delta}=\Ent{\delta}$). 
Let $c'$ be such that $\log(c')=0.99(\log(c)-\Ent{\delta})$, which is by assumption a positive constant. For each $I$ as above, denote the first $\dualcodedim$ coordinates in $I$ by $I'$. 

Note that for a vector $\vec{u}=H\beta^T$ for $\beta\in\Bad{I}{\vec{V}}(C^\bot)$, $\vec{u}[I']$ uniquely determines a $\beta$. This holds since $C^\bot$ is an MDS code, so $H[I']$ is invertible, and determines $\beta$. Consequently, to determine an element in $\Bad{I}{\vec{V}}(C^\bot)$, it suffices to specify it as a sequence of indices into the set $\vec{V}[I']$, where the set $\vec{V}[I']$ is ordered according to some fixed ordering (say, lexicographically).

We thus sometimes denote elements of $\Bad{I}{\vec{V}}(C^\bot)$ as indices $\vec{b}\in [T]^{\dualcodedim}$, and sometimes explicitly as vectors $\beta\in \F^{\dualcodedim}_p$ determined by them (for a fixed $\vec{V},I$). For an index $\vec{b}$, we denote the (unique) corresponding $\beta$ by $\beta_\vec{b}$, and the vector $\vec{u}\in \vec{V}$ such that $\vec{u}=H\beta^T_\vec{b}$ by $\vec{V}_{I,\vec{b}}$.
From now on, by $\vec{V}$ we implicitly refer to $\vec{V}\in {\binom{\F_p}{T}}^n$ and by $I$ we implicitly denote elements of $\binom{n}{(1-\delta)n}$ (with $I'$ defined based on $I$ as above).

\noindent Our plan consists of two steps:
\begin{enumerate}
\item Fix some $\vec{V}$ and $I$ and $Bad'\subseteq [T]^{\dualcodedim}$ of size ${c'}^n$ 
for some $c'$. Prove the fraction of codes for which $Bad'\subseteq \Bad{I}{\vec{V}}(C^\bot)$ is very small. We refer to such codes $C^\bot$ as bad for $(\vec{V},I,Bad')$. 
\item Then, take a union bound over all possible $\vec{V},I$ and possible choices of $Bad'$ as above.
%Note that we may cut the set of possible $Bad'$s, by considering only those $Bad'\in\binom{[T]^{\dualcodedim}}{c'^n}$, which may occur as a subset of some $\Bad{I}{\vec{V}}(C^\bot)$ using some criteria removing `impossible' $Bad'$s (which we develop later).
\end{enumerate}

 %\footnote{The index-based representation of $\Bad{I}{\vec{V}}(C^\bot)$ has the advantage that having fixed $V$, $\bad{I}{\vec{V}}(C^\bot)$ only determines a subset of it. Naively starting with an arbitrary $\Bad{I}{\vec{V}}(C^\bot)$ would require to chose $c^n$ field elements with no additional restrictions, and would render the union bound meaningless.Even now, some of our $\vec{V},I,\Bad{I}{\vec{V}}(C^\bot)$ may not be consistent with any code with the required parameters, but this level of care would suffice for our proof.}

The above plan would already work as is, but would require an even larger, double exponential, $p(n)$. Instead, we observe that each $C^\bot$ that is bad for some $(\vec{V},I,Bad')$, is also `bad' for $(\vec{V},I,B)$ for some $B\subseteq Bad'$ (which is always the case), where $B$ is much smaller than $Bad'$, and has a certain special property. Instead, we bound in step 1 the fraction of the set of $C^\bot$ bad for $(\vec{V},I,B)$, for $B$'s as above, and take a union bound over these in step 2. Here, we gain in step 2, since the number of triples is much smaller than before. 
As before, the bound for $(\vec{V},I,B)$ we get in step 1 decreases with $p$, but now we can afford making $p(n)$ only single exponential, due to the smaller number of summands in 2.

We proceed to show how $B$ is derived from $Bad'$.
\begin{observation}\label{clm:basis}
Let $(\vec{V},I,Bad')$ where $Bad'\in \binom{[T]^{\dualcodedim}}{c'^n}$ and $C^\bot$ bad for it.  
Then, there exists $B\subseteq Bad'$ of size $r=\theta(n)$, such that
$\{\vec{V}_{I,\vec{d}}|\vec{d}\in B\}$ consists of linearly independent vectors. In particular, $C^\bot$ is bad for $(\vec{V},I,B)$  (by definition of bad for $(\Vec{V},I,D)$ for some $D\subseteq [T]^{k^\bot}$).
\end{observation}

\begin{proof}
We observe that $\big\{\vec{V}_{I,\vec{b}}[I]\big\}_{\vec{b}\in Bad'}$ has rank at least $r=\frac{\log(c')}{\log{T}}n$. The observation follows immediately from applying Claim~\ref{rank} to $M=(H\beta^T_1[I'];\ldots;H\beta^T_{c'^n}[I'])$
where $Bad'=\{\beta^T_1,\ldots,\beta^T_{c'^n}\}$ (indeed, note that $|rows(M)|=2^{|cols(M)|\tilde{c}}$ for some constant $\tilde{c}$, since $cols(M)=\dualcodedim=\Theta(n)$, so the precondition of the claim holds). We set $B$ to be a basis of $M$'s rows.
\end{proof}

Next, following our plan outlined above, we bound the fraction of $C^\bot$'s bad for a given $(\vec{V},I,B)$, where $B$ is as guaranteed by Claim~\ref{clm:basis} for $(\vec{V},I,Bad')$ where $Bad'\in \binom{[T]^{\dualcodedim}}{c'^n}$. 

\begin{claim} \label{clm:probbad}
Let $\vec{V},I,B$ where $B\in \binom{[T]^{\dualcodedim}}{c'^n}$ and $D=\{\vec{V}_{I,\vec{d}}|\vec{d}\in B\}$ consists of linearly independent vectors. Then, 
\begin{align}
Pr_{C^\bot\in\mdscode{n}{\dualcodedim}{\F_p}}\Big[C^\bot\text{ is bad for }(\vec{V},I,B)\Big]=p^{-\Omega(n^2\log{p})}
\end{align}
\end{claim}

\begin{proof}
We sample a uniformly $C^\bot$ by sampling its generating matrix $H$.
As the code should be MDS, every set of $\dualcodedim$ rows of $H$ form a basis for $rows(H)$. In particular, given $I$, $H[I']$ is a basis of its row set. 
For simplicity of notation, we assume w.l.o.g.\ that
$I'=[1,\ldots,\dualcodedim]$. Then to determine the rest of $H[I]$ (which is the part we will be interested in), we should set the variables $\alpha_{i,j}$ in
$$h_i=\sum_{j\in[I']}\alpha_{i,j} h_j$$ 
for each $i\in I \setminus I'$.

\noindent In fact, we do not directly sample the matrix $H[I]$ to be consistent with and MDS code, but rather
sample it according to the following distribution $\mathcal{D}_H$,
\begin{enumerate}
\item First sample $h_1,\ldots,h_{\dualcodedim}$ as random linearly independent vectors.   
\item Sample the $\alpha_{i,j}$s as random independent element of $\F_p$.
\end{enumerate}


\noindent We require that $H$ satisfies the following constraints
\begin{enumerate}
\item Every $\dualcodedim$ rows in the resulting $H[I]$ are linearly independent (to actually obtain $H[I]$ consistent with an MDS code). Let us denote this event by $E_1$. 
\item %Assuming the $\alpha_{i,j}$'s satisfy condition 1, 
Every resulting row $h_i$ is consistent with each $\vec{V}_{I,\vec{d}}$ for each $\vec{d}\in B$. 
Let us denote this event by $E_2$.
\end{enumerate}

Let us explicitly state condition 2.
For each $\vec{d}\in B$, and $i\in I\setminus{I'}$ we have
\begin{align}\label{eq:key} 
\sum_{j\in [I']}\alpha_{i,j}\vec{V}_{I,\vec{d}}[j]=\vec{V}_{I,\vec{d}}[i].
\end{align}

That is, having fixed $H[I']$, $H[I\setminus I']$ satisfies 
a linear equation system of the form
\begin{align}
 M_B\alpha^T_i=v_i \label{eq:key2}
\end{align}
where $M_B\in \F^{r\times \dualcodedim}$ is a full-rank matrix, whose rows are elements in $\big\{\vec{V}_{I,\vec{b}}[I']\big\}_{\vec{b}\in Bad'}$.
We are now ready to prove our theorem - in particular, note that $M_B$ depends only on $\vec{V},I,B$, rather than on the code itself. 
This follows as 
$$\vec{V}_{I,\vec{d}}[i]=H\beta^T_{\vec{d}}[i]=H[i]\beta^T_{\vec{d}}$$
Making the same observation on the left side, together with $h_i=\sum_{j\in [I']}\alpha_{i,j}h_j$ implies Equation~\ref{eq:key}.
We can restate Equation~\ref{eq:key}, as requiring that every $\alpha_i$ satisfies a linear equation system
$M_B\alpha^T_i=\vec{\tilde{u}}_i$, where $M_B$ is invertible (note that $M_B$ is the same for all $i$).

Now we prove that the probability (over a uniform choice of all $\alpha_{i,j}\in \F_p$ and $H[I']$) that constraint 2 holds conditioned on constraint 1 holding, is $p^{-\Omega(\dualcodedim^2\log(p))}$.
That is, we prove
\begin{align}
    Pr_{H\leftarrow \mathacal{D}_H}[C^\bot \in E_2| C^\bot E_1] &\leq \nonumber\\\nonumber \\ 
     \frac{Pr_{H\leftarrow \mathacal{D}_H}[C^\bot \in E_2]}{Pr_{H\leftarrow \mathacal{D}_H}[C^\bot \in E_1]} &= p^{-\Omega(n^2\log{p})} \label{eq:probbound}
\end{align}
To prove Equation~\ref{eq:probbound}, we bound the denominator and the numerator of the expression in~\ref{eq:probbound} separately.

\begin{claim} \label{clm:E2} %%% Claim 4.0.3
$Pr_{H\leftarrow \mathcal{D}_H}[C^\bot \in E_2]=p^{-\Omega(n^2\log{p})}$
\end{claim}

\begin{proof}
Consider having chosen the first $h_1,\ldots,h_{\dualcodedim}$ in $H$ (which are linearly independent). Next we move to picking the rows in $I\setminus I'$, represented in basis $h_1,\ldots,h_{\dualcodedim}$ for convenience (by choosing the $\alpha_{i,j}$s).
Consider the next $i\in I\setminus{I'}$ for which we pick $h_i$.
By properties of linear transformations, and Equation~\ref{eq:key2}, every such coefficient vector $\alpha_i$, belongs to a coset $K+x_i$ of the right kernel $K$ of $M_B$, for some $x_i\in \F^r_p$. %There are at most $T^{(1-\delta)n-\codedim}\leq T^n$ such cosets.
Therefore, a randomly chosen such vector $\alpha_i$ only satisfies the above condition with probability $q = p^{-r}$,
since $|K|=\F^{\dualcodedim-r}$ by the rank-nullity theorem.
Note that this holds independently of the concrete choice of $H[I']$.
Now, $q$ equals $p^{-\Theta(n)}$, since indeed $r=\Theta(n)$ by Observation~\ref{clm:basis}, and $\dualcodedim=\Theta(n)$ by the choice of $\delta$.
As the choice of each $h_i$ is independent of the choice of $h_j$ for every $i,j\in I\setminus{I'}$, the overall probability of the event $E_2$ is 
\begin{align} \label{eq:probE2}
&\prod_{i\in I\setminus{I'}}p^{-r}=p^{-r((1-\delta)n-\dualcodedim)}=p^{-\Theta(n^2)}
\end{align}
\end{proof} %End Claim 4.0.3 Proof

\begin{claim} \label{clm:E1} %%% Claim 4.0.4
$Pr_{H\leftarrow \mathcal{D}_H}[C^\bot \in E_1]>1/2$ assuming $p(n)\geq 2^n$.
\end{claim}

\begin{proof}
Consider the process of randomly choosing the rows in $H[I\setminus{I'}]$, after picking $H[I']$ according to $\mathcal{D}_H$. We pick the rows $h_i$ ($i\in I\setminus{I'}$) one by one. For each row $h_i$ being picked, let us denote the set $\tilde{I}$ of rows picked so far (including $H[I']$ and excluding $h_i$).
We require that the invariant, that every $\dualcodedim\times \dualcodedim$ submatrix of $H[\tilde{I}\cup\{i\}]$ remains invertible, is not broken upon choosing $h_i$. 
To keep the invariant, we need that every submatrix $\tilde{H}$ of $H[\tilde{I}]$ with $\dualcodedim-1$ rows, remains invertible when appending $h_i$ to it.
In the worst case - when choosing the last row, we have at least a fraction 
\begin{align}
1 - {\binom{n}{\dualcodedim}}/p>1/2 \label{eq:frac}
\end{align}
of vectors in $\F^{\dualcodedim}_p$ to choose from. 
This follows by taking a union bound over all submatrices $\tilde{H}$ as above.
Indeed, complementing each $\tilde{H}$ succeeds with probability $1-1/p$. Picking $p(n)$ large enough - $p(n)\geq 2^n$ suffices, keeps Equation~\ref{eq:frac} true.
\end{proof} %End Claim 4.0.4 Proof
Now, Equation~\ref{eq:probbound}, follows immediately from Claim~\ref{clm:E2} and Claim~\ref{clm:E1}, which completes the proof of Claim~\ref{clm:probbad}.
\end{proof} %End Claim 4.0.2 Proof


Back to the proof of Lemma~\ref{lem:sim} (following step 2 of the plan), we take a union bound over all possible 
$\vec{V}\in \binom{\F_p}{T}^n,I\in \binom{[n]}{(1-\delta)n},B\in \binom{[T]^{\dualcodedim}}{r}$. By a crude estimation, there exist at most
$${\binom{p}{T}}^n(2^n)(T^{{\dualcodedim} n})=2^{O((\log{p}+{\dualcodedim}) n)}$$
such triples. Thus, from Claim~\ref{clm:probbad}, the probability of $C^\bot$ being bad for $(n,\delta,c,T)$
is upper bounded by
$$2^{\log{p}(O(n) - \Omega(n^2)) + O(n^2))}=2^{n^2(\Omega(\log{p})+O(1))}=2^{\Omega(-n^3)}=neg(n),$$ 
where the last equality is implied by $\log{p}=\Omega(n)$.
This concludes the proof of Lemma~\ref{lem:sim}.
\end{proof} %End Lemma 4.0.1 Proof (\label{lem:sim})

%As $H[I',*]$ forms a basis of $H$'s row space, $H[I',*]$ is invertible. We may therefore express $H[I\setminus{I'},*]$'s rows in the basis formed by $H[I',*]$'s rows. Assume w.l.o.g.\ that $I'=[1,\ldots,\dualcodedim]$. 
%Then each $h_i$ for $i\in I\setminus{I'}$ satisfies the following equation in the $\alpha_{i,j}$'s: $h_i=\sum_{j\in[I']}\alpha_{i,j} h_j$. Consider some basis $B$ of 
%$\{\vec{V}_{I,\vec{b}}[I]\}_{\vec{b}\in Bad'}$, taken from the set itself - assume it corresponds to indices $b_1,\ldots,b_r$. 

%For each $b_y\in B$, we have
%$\sum_{j\in [I']}\alpha_{i,j}\vec{V}_{I,b_y}[j]=\vec{V}_{I,b_y}[i].$
%That is, having fixed $H[I']$, $H[I\setminus I']$ satisfies 
%a linear equation system of the form
%$M_B\alpha^T_i=v_i$ where $M_B\in \F^{r\times \dualcodedim}$ is a full-rank matrix, whose rows are elements in $\big\{\vec{V}_{I,\vec{b}}[I']\big\}_{\vec{b}\in Bad'}$.
%We are now ready to prove our theorem - in particular, note that $M_B$ depends only on $\vec{V},I,B$, rather than on the code itself. 

%Now, to improve the resulting bound on field size, we update plan 1+2 to consider bad codes for $(\vec{V},I,B)$, and take a union bound on all possible triples. For a given $(\vec{V},I,B)$, we denote the fraction of codes bad for it by $bc_{\vec{V},I,B}$.


\begin{theorem}\label{thm:mostmds}
Let $0<\delta<1$ and $m\in\mathbb{N}^+$ be constants, where $\delta$ is sufficiently small\footnote{The strange situation where we handle small $\delta>0$ but not larger $\delta$ is an artifact of the proof of Lemma~\ref{lem:sim}. A slightly more complicated proof would remove this restriction. See the full version for details.}. Then for every field size function $p(n)\geq 2^n$ outputting primes, every sufficiently large $n$, and every $\codedim \geq (0.5 + \delta/2)n$, the Massey secret  sharing scheme $(Sh_C,Rec_C)$ corresponding to a random linear$ \mdscode{n}{\codedim}{\F_p}$ code $C$, allows for a local leakage of $m$ bits from each party's secret share and leakage error $\leq 2^{-\Omega(n)}$ with overwhelming probability $1-neg(n)$.  
\end{theorem}
% NOTE: I am still in the middle of writing up all the proofs.
% The constant for m=1 is the best, I am yet to calculate it. It is something circa 0.48n

\begin{proof}
\noindent{\bfseries Proof overview.} 
We consider the hardest case of $\codedim=(0.5 + \delta/2)n$. 
Note that since the dual of a linear $\mdscode{n}{\codedim}{\F_p}$ code $C$ is a linear $\mdscode{n}{\dualcodedim = n-\codedim=(0.5-\delta/2)n}{\F_p}$ code $C^\bot$, a random $C$ as above (as considered in the theorem), can be uniformly sampled by uniformly sampling an $\mdscode{n}{\dualcodedim}{\F_p}$ (and taking the dual $C=(C^\bot)^\bot$).
Indeed, it will be more convenient to consider sampling of $C^\bot$ throughout the proof. 
We use the probabilistic method to prove that the $C^\bot$ based expression for $\SD{\vec{L}(C)}{\vec{L}(\F^n_p)}$ from Claim~\ref{clm:dual} is small for `almost all' codes $C^\bot$. This will correspondingly imply the Theorem for almost all codes $C$ as required. 

Our proof proceeds by applying Lemma~\ref{lem:sim} to $\vec{V}$, where each $V_i$ represents a set of values $\alpha_i\in \F_p$ corresponding to Fourier coefficients with  `large' (say $\geq 0.01$) absolute value, of any of the local leakage functions $\widehat{\vec{1}}_{\ell_i}$. 

On a high level, we prove that with overwhelming probability, for a random $\mdscode{n}{\dualcodedim}{\F_p}$ code $C^\bot$, not only that every non-0 codeword has less than $\dualcodedim$ 0-coordinates (which holds for every MDS code), but also, for every vector of boolean functions $(\vec{1}_{\ell_1},\ldots,\vec{1}_{\ell_n})$, very few codewords $(\alpha_1,\ldots,\alpha_n)$ have a `large' number of `large' coefficients (say, coefficients larger than $0.01$).
That is, 0-coefficients $|\widehat{\vec{1}}_{\ell_i}(\alpha_i=0)|$ are large in absolute value, and contribute a lot to the bound in Claim~\ref{clm:dual} if a lot of them `come together' in a single codeword. Indeed the 0-coefficient is the largest in absolute value for all boolean functions $f$. 

However, if possibly smaller but still large coefficients  (including the 0-coefficient, and a few other that are function-specific)
tend to `come together' sufficiently often in a single codeword, this also pushes the bound up, albeit a bit slower. We can afford more such `somewhat heavy' codewords, but not much more. In our previous analysis for Shamir, we gained a little by pinpointing the locations of the 0-coefficients exactly, instead of assuming the worst possible ($\dualcodedim$) number of 0's in every codeword, as done in~\cite{EPRINT:BDIR19}. 

Here we go a step forward, and prove that for almost all $C^\bot$'s as above, for every leakage functions vector $\vec{L} \in {\mathcal{L}}_{m,n,p}$, only few sufficiently `heavy' codewords $H\cdot \beta$ (where `too many' of the coefficients $(\widehat{\vec{1}}_{\ell_1}(\alpha_1),\ldots,\widehat{\vec{1}}_{\ell_n}(\alpha_n))$ are large) exist. Details follow.\\

%Fix some small constant $0<\delta<1$ with an upper bound to be fixed later. 

A key technical observation our proof relies on, is that for any function $f:\F_p\rightarrow \{0,1\}$, there are very few large Fourier coefficients.
More precisely, for constant (independent of $p$) $\epsilon$ let us define $\SBig{f}{\epsilon}=\{\alpha\in\F_p|\widehat{f}(\alpha) \geq \epsilon\}$. Then we have,

\begin{claim}\label{clm:heavy}
Let $p$ be a prime, and let $f:\F_p\rightarrow\{0,1\}$ be a boolean function.
Then, for any $\epsilon\in(0,1]$, $| \SBig{f}{\epsilon}|\leq\epsilon^{-2}$. 
\end{claim} 

\noindent The above simple fact follows immediately from Parseval's identity,
$$\sum_{\alpha\in\F_p}{\widehat{f}}^2(\alpha)=|f^{-1}(1)|/p\leq 1$$

%Next, consider a sufficiently small constant $\epsilon>0$ to be fixed later.
%Let $\delta=log(1/\epsilon)$.

\noindent By Claim~\ref{clm:dual}, we have:
\begin{align}
\SD{\vec{L}(C)}{\vec{L}(\mathbb{F}^n_p)}=\sum_{\vec{\ell}}\left|\sum_{\beta\in 
\F^{\codedim}_p\setminus{\{0\}}}\prod^n_{i=1}\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})\right|.
\end{align}



\noindent Rearranging, we obtain an upper bound
\begin{align}
&\SD{\vec{L}(C)}{\vec{L}(\mathbb{F}^n_p)}\leq \sum_{\beta\in 
\F^{\codedim}_p\setminus{\{0\}}}\sum_{\vec{\ell}}\left|\prod^n_{i=1}\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})\right|\label{eq:8}
\end{align}

%Given a leakage vector $\vec{L}=(L_1,\ldots,L_n) \in {\mathcal{L}}_{m,n,p}$. 
We now consider parameters $c,\delta,\epsilon,T=\lceil 2^m\epsilon^{-2}\rceil$ for $c,\epsilon,\delta$ to be determined later in a way satisfying the conditions of Lemma~\ref{lem:sim}.
Then, a random $\mdscode{n}{\dualcodedim}{\F_p}$ code $C^\bot$ satisfies the condition of Lemma~\ref{lem:sim} with overwhelming probability. Fix any such code $C^\bot$ and let $H$ be its generating matrix.

Consider the sequence $\vec{V}=(V_1,\ldots,V_n)\subseteq {\binom{\F_p}{T}}^n$ where 
$V_i = \bigcup_{\ell_i\in \{0,1\}^m} \SBig{\vec{1}_{\ell_i}}{\epsilon}$ \footnote{Padding $V_i$ to size $T$ arbitrarily} is the set of all values of codeword coordinate $\alpha_i$ corresponding to a large coefficient for some function $\vec{1}_{\ell_i}$. 
\footnote{In particular, the $V_i$'s will always include 0. We could further limit the structure of $V$ in Lemma~\ref{lem:sim}, for instance, that $V_i$ consists of pairs of values of the form $\alpha,-\alpha$, but as it seemingly does not help improve our bounds, we do not.}

%\paragraph{Proof of Lemma~\ref{lem:sim}}
Let $\BadNoZero{\vec{V}}{\delta}=\Bad{\vec{V}}{\delta}(C^\bot) \setminus \{0\}$, $\GoodNoZero{\vec{V}}{\delta}=\F^{\dualcodedim}_p\setminus(\BadNoZero{\vec{V}}{\delta}\cup\{0\})$. For a set $I\subseteq [n]$, we denote \[\GoodNoZero{\delta}{I}=\{\beta\in \GoodNoZero{\vec{V}}{\delta}| \forall i\in I\;(H\beta^T[i]\notin V_i)\}\]
Next, we split the sum in Equation~\ref{eq:8} applied to $C=(C^\bot)^\bot$ as follows, 
\begin{align}
&\SD{\vec{L}(C)}{\vec{L}(\mathbb{F}^n_p)}\leq\nonumber\\
& \sum_{\beta\in \GoodNoZero{\vec{V}}{\delta}}\sum_{\vec{\ell}}\left|\prod^n_{i=1}\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})\right| 
  + \sum_{\beta\in \BadNoZero{\vec{V}}{\delta}}\sum_{\vec{\ell}}\left|\prod^n_{i=1}\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})\right|
\end{align}

Let us bound each of the two summands separately. %Consider the first summand.
%We split the set $Good_{I_1,V}$ into two sets, $\GoodNoZero{\vec{V}}{\delta},\BadNoZero{\vec{V}}{\delta}$. $\GoodNoZero{\vec{v}}{\delta}$ is the set of all vectors
%$\beta$, such that $|\{i\in I_1|\ip{\beta,h_i}\in V_i\}|\geq (1-\delta) n/3$.
%By choice of $C^\bot$, $|\BadNoZero{\vec{V}}{\delta}|\leq 2^{cn}$. 
For a given $I \subseteq [n]$, let us denote by $I_1,I_2$ a partition of $[n]\setminus I$ into two subsets of equal size, in some predetermined way (depending only on $I$). 
We bound the contribution of $\GoodNoZero{\vec{V}}{\delta}$ first,
{\allowdisplaybreaks
\begin{align}
&\sum_{\beta\in \GoodNoZero{\vec{V}}{\delta}}\sum_{\vec{\ell}}\left|\prod^n_{i=1}\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})\right|\leq\nonumber\\
%%% 4.7
&\sum_{I\in{\binom{[n]}{\delta n}[n]}}\sum_{\beta\in \GoodNoZero{\delta}{I}}\sum_{\vec{\ell}}\left|\prod^n_{i=1}\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})\right|\label{eq-CS7} \leq \\
%%% 4.8
&\tilde{O}(2^{\Ent{\delta}n}) \cdot \max_I\Bigg(\sqrt{\sum_{\beta\in \GoodNoZero{\vec{V}}{\delta}}\prod_{i\in I_1}\Big(\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|^2\Big)}\cdot\sqrt{\sum_{\beta\in \GoodNoZero{\vec{V}}{\delta}}\prod_{i\in I_2}\Big(\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|^2\Big)}\cdot \nonumber \\ 
%%% 4.8
& \hphantom{{}=\tilde{O}(2^{\Ent{\delta}n})\max_I}\max_{\beta\in \GoodNoZero{\vec{V}}{\delta}}\prod_{i\in I}\Big(\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|\Big) \Bigg) \leq \label{eq-CS8} \\ 
%====================
&\tilde{O}(2^{\Ent{\delta}n}) \cdot \max_I\Bigg(\sqrt{\sum_{\beta\in \F^{\dualcodedim}_p}\prod_{i\in I_1}\Big(\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|^2\Big)}\cdot\sqrt{\sum_{\beta\in  \F^{\dualcodedim}_p}\prod_{i\in I_2}\Big(\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|^2\Big)}\cdot \nonumber\\
%%% 4.9
& \hphantom{{}=\tilde{O}(2^{\Ent{\delta}n})\max_I} \max_{\beta\in \GoodNoZero{\vec{V}}{\delta}}\prod_{i\in I}\Big(\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|\Big) \Bigg)\leq \label{eq-CS11} \\
&\tilde{O}(2^{\Ent{\delta}n}) \cdot\max_I \Bigg( \sqrt{\prod_{i\in I_1}\Big(\sum_{\ell_i}\sum_{\alpha\in\F_p}|\widehat{\vec{1}}_{\ell_i}(\alpha)|^2\Big)}\cdot\sqrt{\prod_{i\in I_2}\Big(\sum_{\ell_i}\sum_{\alpha\in\F_p}|\widehat{\vec{1}}_{\ell_i}(\alpha)|^2\Big)}\cdot\nonumber\\
%%% 4.10
& \hphantom{{}=\tilde{O}(2^{\Ent{\delta}n})\max_I} \max_{\beta\in \GoodNoZero{\vec{V}}{\delta}}\prod_{i\in I}\Big(\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|\Big) \Bigg) \leq\label{eq-CS9}\\
%%% 4.11
& \tilde{O}(2^{\Ent{\delta}n})\cdot(2^{2m}\epsilon)^{\delta n}=\tilde{O}(2^{(\Ent{\delta}+\delta(2m+\log{\epsilon}))n})\leq 2^{-\epsilon' n} \label{eq-eps}
\end{align}}

for $\epsilon' > 0$ constant, for a proper choice of $\epsilon$.

Inequality~\ref{eq-CS7} follows by Cauchyâ€“Schwarz.
Let $I$ be the set selected by the  $\max_I$.
Inequality~\ref{eq-CS8} holds since each $\beta\in \F^{\dualcodedim}_p$ contributes a non-negative summand $\prod_{i\in I_1}(\ldots)$ (similarly $I_2$), and all values in the product are non-negative. Thus, adding $\beta$'s beyond $\GoodNoZero{\vec{V}}{\delta}$ can only increase the expression's value.
Inequality~\ref{eq-CS11} holds since $|I_1|,|I_2|=(1-\delta)n/2=(0.5-\delta/2)n$ and this equals exactly $\dualcodedim$. As our code is an MDS code, indeed going over all $\beta\in \F^{\dualcodedim}_p$, contributes exactly 
$$ \prod_{i\in I_1}\Big(\sum_{\alpha\in\F_p}|\widehat{\vec{1}}_{\ell_i}(\alpha)|^2\Big),$$
for each fixed vector of $(\ell_i)_{i\in I_1}$. \footnote{We should indeed make sure that the rounding works out and $(0.5-\delta/2)n$ is integral and even, because otherwise, if $I_1$ is smaller by 1 than $\dualcodedim$, every $\prod_{i\in I_1}\Big(\sum_{\alpha\in\F_p}|\widehat{\vec{1}}_{\ell_i}(\alpha)|^2\Big)$ would appear $p$ times, causing the whole $\sqrt{\prod_{i\in I_1}(\ldots)}$ expressing be multiplied  by $\sqrt{p}$.}
A similar analysis holds for the other $\sqrt{\ldots}$ and $I_2$.

The inequality~\ref{eq-CS9} follows by observing that for every fixed $\ell_i$, $\sum_{\alpha\in\F_p}|\widehat{\vec{1}}_{\ell_i}(\alpha)|^2=\frac{|\vec{1}^{-1}_{\ell_i}(1)|}{p}$ by Parseval's identity, which is upper bounded by $1$. So, summing over all $2^m$ of the $\ell_i$ values results in $2^m$. This implies a $2^{m\delta n}$
bound on the product of the two squares. 
%In the $\max_{\beta\in \GoodNoZero{\vec{V}}{\delta}}$ part, for each $i \in I$ 
%\begin{align}\label{eq:9}
%&\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|\leq 1
%\end{align}
%This holds since for boolean functions $f$, every coefficient $\widehat{f}(\alpha)$
%contributes is at most as large as the 0-coefficient, which is precisely
%$Pr_{x\in \F_p}[f(x)=1]$. As in our case, the %probabilities over the two values of $\ell_i$ %sum up to exactly 1, the observation follows. 
Now, each $i\in I$ satisfies $\sum_{\ell_i}|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})|\leq 2^m\epsilon$. This is guaranteed to hold for every $\beta\in \GoodNoZero{\vec{V}}{\delta}$, by the choice of $C^\bot$. Thus, the product of the two contributions is bounded by $2^{m\delta n}(2^m\epsilon)^{\delta n}=(2^{2m}\epsilon)^{\delta n}$.

The inequality~\ref{eq-eps} follows by choosing 
\begin{equation}
\epsilon < 2^{-(\Ent{\delta}/\delta+2m)} \label{epsilonBound},
\end{equation}
so $\epsilon'>0$ is indeed constant,  which concludes the analysis of the bound on $\GoodNoZero{\vec{V}}{\delta}$'s contribution.


The contribution of $\Bad{\setminus\{0\}}{(1-\delta)}$ requires somewhat more care. In particular, we need to show that every fixed $\beta$ makes a contribution which is (much) smaller than 1. We have 
\begin{align}
& \sum_{\beta\in \BadNoZero{\vec{V}}{\delta}}\sum_{\vec{\ell}}\left|\prod^n_{i=1}\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})\right|\leq \nonumber\\
& \sum_{\beta\in \BadNoZero{\vec{V}}{\delta}}\prod^n_{i=1}\Big(\sum_{\ell_i}\left|\widehat{\vec{1}}_{\ell_i}(\ip{\beta,h_i})\right|\Big)\leq\label{eq:applem}\\
& c^n\cdot c^{(0.5 + \delta/2)n}_m = 2^{n\left( \log{c}+(0.5+\delta/2)\log{c_m} \right)}\leq 2^{-\epsilon' n}\label{eq:2epsilon}
\end{align}

for $\epsilon' >0$ constant, for a proper choice of $c$ and $\delta$.

Inequality~\ref{eq:applem} holds since by Lemma~\ref{lem:sim}, we have  $|\Bad{\setminus\{0\}}{(1-\delta)}|\leq c^n$. The second term in the expression $c^n\cdot c^{(0.5 + \delta/2)n}_m$ follows from Lemma~\ref{lem:sumlibound}, applied to each $i\in [n]$, for each fixed $\beta\in \BadNoZero{\vec{V}}{\delta}$. In our case, at most $(0.5-\delta/2)n$ (note that $\dualcodedim-1 <(0.5-\delta/2)n$) coordinates $\ip{\beta,h_i}$ of the codeword $\alpha=H\beta^T$ equal 0, since $\BadNoZero{\vec{V}}{\delta}$ does not contain $\beta = \vec{0}$ and our code $C^\bot$ is MDS. 
Therefore, the contribution of the non-0 coordinates (at least $(0.5+\delta/2)n$ coordinates) to the product accounts to at most $c^{(0.5+\delta/2)n}_m$.
%Now, as every $\beta\in \GoodNoZero{\vec{V}}{\delta}$ is not $0$, there are overall at least $(1/2 + \delta/2)n$ non-zero


The inequality~\ref{eq:2epsilon} and everything so far that relies on Lemma~\ref{lem:sim} follows by choosing 
\begin{align}
    &c \leq c^{-0.5}_m\label{eq:11}\;\;\;\;\;\text{and}\\
    &c \geq 2^{\Ent{\delta}}.\label{eq:12} 
\end{align}

The requirement~\ref{eq:11} suffices to ensure $\epsilon' >0$, since $\delta> 0$. In particular, $c$ satisfying requirement~\ref{eq:11} can be chosen to be a constant strictly larger than 1, since $c_m$ is a constant that falls in $(0,1)$.
The requirement~\ref{eq:12} is to satisfy the precondition $\log(c)>\Ent{\delta}$ of Lemma~\ref{lem:sim}.
%In addition, such a choice of $c$ suffices to sataisfy the preconditions of Lemma~\ref{lem:sim}, since $0<c_m<1$.
%It is easy to see one can set $c,\epsilon$ so that Equations~\ref{eq:11},~\ref{eq:12} and~\ref{eq:9} are satisfied, since $0<c_m<1$. 
To satisfy requirement~\ref{eq:12}, we would need to set $\delta>0$ to be a very small constant, and $\epsilon$ about $2^{-\Theta_m(\delta)}$ by requirement~\ref{epsilonBound}.
This is inconsequential to the scheme's parameters in the current setting. \footnote{It only increases $T$ in Lemma~\ref{lem:sim}, which only possibly affects the smallest $n$ for which a code $C^\bot$ is guaranteed to exist.}
\end{proof}
